{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "du0YTSQdBWCI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import opendatasets as od\n",
        "import pandas\n",
        "from PIL import Image\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import functools\n",
        "import random\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/omkargurav/face-mask-dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcxCa9Cdqs2N",
        "outputId": "869443ff-13a3-4264-de15-3a8af69a8161"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: beta10\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/omkargurav/face-mask-dataset\n",
            "Downloading face-mask-dataset.zip to ./face-mask-dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163M/163M [00:04<00:00, 37.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with_mask_path = '/content/face-mask-dataset/data/with_mask/*'\n",
        "without_mask_path = '/content/face-mask-dataset/data/without_mask/*'\n",
        "\n",
        "# need to randomize the images within themselves\n",
        "# mask -> 1, without mask -> 0\n",
        "# train_images = np.array([np.array(Image.open(fname).resize((64, 64))) for fname in glob.glob(with_mask_path)])\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# with mask\n",
        "for file in glob.glob(with_mask_path):\n",
        "  np_image = np.array(Image.open(file).resize((64, 64)))\n",
        "\n",
        "  if np_image.shape == (64, 64, 3):\n",
        "    images.append(np_image)\n",
        "    labels.append(np.array([1]))\n",
        "\n",
        "# without mask\n",
        "for file in glob.glob(without_mask_path):\n",
        "  np_image = np.array(Image.open(file).resize((64, 64)))\n",
        "\n",
        "  if np_image.shape == (64, 64, 3):\n",
        "    images.append(np_image)\n",
        "    labels.append(np.array([0]))\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yVJJ7LWzsyBf"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "images, labels = unison_shuffled_copies(images, labels)\n",
        "images = images.astype('float32')\n",
        "labels = labels.astype('float32')\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyTs2LcNDzMF",
        "outputId": "c21bb372-cd9f-4350-e5da-5148a1c5095a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7544, 64, 64, 3)\n",
            "(7544, 1)\n",
            "[[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " ...\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(size):\n",
        "  batch_images = []\n",
        "  batch_labels = []\n",
        "  for i in range(size):\n",
        "    index = random.randint(0, 7543)\n",
        "    batch_images.append(images[index])\n",
        "    batch_labels.append(labels[index])\n",
        "  return (np.array(batch_images), np.array(batch_labels))\n",
        ""
      ],
      "metadata": {
        "id": "5rSag4AIW3P2"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Define the CNN model ###\n",
        "\n",
        "n_filters = 12 # base number of convolutional filters\n",
        "\n",
        "def make_standard_classifier(n_outputs=1):\n",
        "  Conv2D = functools.partial(tf.keras.layers.Conv2D, padding='same', activation='relu')\n",
        "  BatchNormalization = tf.keras.layers.BatchNormalization\n",
        "  Flatten = tf.keras.layers.Flatten\n",
        "  Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    Conv2D(filters=1*n_filters, kernel_size=5,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters=2*n_filters, kernel_size=5,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters=4*n_filters, kernel_size=3,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters=6*n_filters, kernel_size=3,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512),\n",
        "    Dense(n_outputs, activation=None),\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "standard_classifier = make_standard_classifier()"
      ],
      "metadata": {
        "id": "qD2VqS7MQH6m"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Train the standard CNN ###\n",
        "\n",
        "# Training hyperparameters\n",
        "params = dict(\n",
        "  batch_size = 32,\n",
        "  num_epochs = 2,  # keep small to run faster\n",
        "  learning_rate = 5e-4,\n",
        "  train_size = 5000,\n",
        ")\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(params[\"learning_rate\"]) # define our optimizer\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "\n",
        "@tf.function\n",
        "def standard_train_step(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # feed the images into the model\n",
        "    logits = standard_classifier(x)\n",
        "    # Compute the loss\n",
        "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "\n",
        "  # Backpropagation\n",
        "  grads = tape.gradient(loss, standard_classifier.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, standard_classifier.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "# The training loop!\n",
        "step = 0\n",
        "for epoch in range(params[\"num_epochs\"]):\n",
        "  for idx in tqdm(range(params[\"train_size\"] // params[\"batch_size\"])):\n",
        "    # Grab a batch of training data and propagate through the network\n",
        "    x, y = get_batch(params[\"batch_size\"])\n",
        "    loss = standard_train_step(x, y)\n",
        "\n",
        "    step += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfC3kabDQKnM",
        "outputId": "908152e2-ac5a-45e4-8e9e-dbbfbfa098c7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 156/156 [00:10<00:00, 14.43it/s]\n",
            "100%|██████████| 156/156 [00:10<00:00, 15.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Evaluation of standard CNN ###\n",
        "\n",
        "# TRAINING DATA\n",
        "# Evaluate on a subset of CelebA+Imagenet\n",
        "(batch_x, batch_y) = get_batch(2500)\n",
        "y_pred_standard = tf.round(tf.nn.sigmoid(standard_classifier.predict(batch_x)))\n",
        "acc_standard = tf.reduce_mean(tf.cast(tf.equal(batch_y, y_pred_standard), tf.float32))\n",
        "\n",
        "print(\"Standard CNN accuracy on training set: {:.4f}\".format(acc_standard.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8ZLngBmQQIJ",
        "outputId": "d7d73c1a-d9b1-459c-ce5d-aaac91a0c39e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 2s 24ms/step\n",
            "Standard CNN accuracy on training set: 0.9276\n"
          ]
        }
      ]
    }
  ]
}